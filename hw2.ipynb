{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-12T10:07:51.875836Z",
     "start_time": "2023-10-12T10:07:51.506958Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from datetime import datetime\n",
    "import wandb\n",
    "import argparse\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TitanicDataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27ac2968f1ddf940"
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "outputs": [],
   "source": [
    "class TitanicDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        '''데이터셋 초기화'''\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.y = torch.LongTensor(y)\n",
    "        \n",
    "    def __len__(self):\n",
    "        '''데이터셋 전체 길이를 반환'''\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        '''데이터셋의 특정 인덱스(feature) 반환'''\n",
    "        feature = self.X[idx]\n",
    "        target = self.y[idx]    # 타겟 데이터\n",
    "        return {'input':feature, 'target': target}\n",
    "    \n",
    "    def __str__(self):\n",
    "        '''데이터셋의 정보 알려주는 함수'''\n",
    "        str = \"Data Size: {0}, Input Shape: {1}, Target Shape: {2}\".format(len(self.X), self.X.shape, self.y.shape\n",
    "        )\n",
    "        return str"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T10:07:51.883921Z",
     "start_time": "2023-10-12T10:07:51.518122Z"
    }
   },
   "id": "be9dc305e1eaacb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TitanicTestDataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "befb26f7ad18b7d1"
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [],
   "source": [
    "class TitanicTestDataset(Dataset):\n",
    "  def __init__(self, X):\n",
    "    self.X = torch.FloatTensor(X)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.X)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    feature = self.X[idx]\n",
    "    return {'input': feature}\n",
    "\n",
    "  def __str__(self):\n",
    "    str = \"Data Size: {0}, Input Shape: {1}\".format(\n",
    "      len(self.X), self.X.shape\n",
    "    )\n",
    "    return str"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T10:07:51.884924Z",
     "start_time": "2023-10-12T10:07:51.518890Z"
    }
   },
   "id": "816a011f6f9b63d5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# get_preprocessed_dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11802ab4f9f11340"
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [],
   "source": [
    "def get_preprocessed_dataset():\n",
    "    # 파일의 절대 경로 설정\n",
    "    CURRENT_FILE_PATH = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "    \n",
    "    # train.csv 파일 경로 설정\n",
    "    train_data_path = os.path.join(CURRENT_FILE_PATH, \"train.csv\")\n",
    "    # test.csv 파일 경로 설정\n",
    "    test_data_path = os.path.join(CURRENT_FILE_PATH, \"test.csv\")\n",
    "    \n",
    "    train_df = pd.read_csv(train_data_path)\n",
    "    test_df = pd.read_csv(test_data_path)\n",
    "    \n",
    "    # train.csv : PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Enbarked\n",
    "    # test.csv : PassengerId, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Enbarked\n",
    "    # 데이터프레임을 연결할 때 컬럼의 순서나 이름이 일치하지 않아도, 해당 컬럼 이름이 존재하는 경우 데이터를 합침\n",
    "    all_df = pd.concat([train_df, test_df], sort=False)\n",
    "\n",
    "    all_df = get_preprocessed_dataset_1(all_df)\n",
    "\n",
    "    all_df = get_preprocessed_dataset_2(all_df)\n",
    "\n",
    "    all_df = get_preprocessed_dataset_3(all_df)\n",
    "\n",
    "    all_df = get_preprocessed_dataset_4(all_df)\n",
    "\n",
    "    all_df = get_preprocessed_dataset_5(all_df)\n",
    "\n",
    "    all_df = get_preprocessed_dataset_6(all_df)\n",
    "\n",
    "    train_X = all_df[~all_df[\"Survived\"].isnull()].drop(\"Survived\", axis=1).reset_index(drop=True)\n",
    "    train_y = train_df[\"Survived\"]\n",
    "\n",
    "    test_X = all_df[all_df[\"Survived\"].isnull()].drop(\"Survived\", axis=1).reset_index(drop=True)\n",
    "\n",
    "    dataset = TitanicDataset(train_X.values, train_y.values)\n",
    "    #print(dataset)\n",
    "    train_dataset, validation_dataset = random_split(dataset, [0.8, 0.2])\n",
    "    test_dataset = TitanicTestDataset(test_X.values)\n",
    "    #print(test_dataset)\n",
    "\n",
    "    return train_dataset, validation_dataset, test_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T10:07:51.885264Z",
     "start_time": "2023-10-12T10:07:51.519035Z"
    }
   },
   "id": "dc72ab58f2f199af"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# get_preprocessed_dataset_1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8a1e67d84f93138"
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [],
   "source": [
    "def get_preprocessed_dataset_1(all_df):\n",
    "    '''Pclass별 Fare 평귱값을 사용하여 Fare 결측치 메우기'''\n",
    "    # Pcalss 와 Fare을 선택하여 데이터 추출 후 Pclass로 그룹화\n",
    "    # 그 후 나온 평균 값을 Fare_mean에 저장\n",
    "    Fare_mean = all_df[[\"Pclass\", \"Fare\"]].groupby(\"Pclass\").mean().reset_index()\n",
    "    # Fare_mean 열의 이름을 Pclass 와 Fare_mean으로 변경\n",
    "    Fare_mean.columns = [\"Pclass\", \"Fare_mean\"]\n",
    "    # Fare_mean 데이터프레임을 Pclass 열을 기준으로 left join 하여 병합\n",
    "    # Pclass 열을 기준으로 Fare의 결측치를 Fare_mean 값으로 채울 수 있음\n",
    "    all_df = pd.merge(all_df, Fare_mean, on=\"Pclass\", how=\"left\")\n",
    "    all_df.loc[(all_df[\"Fare\"].isnull()), \"Fare\"] = all_df[\"Fare_mean\"]\n",
    "    \n",
    "    return all_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T10:07:51.888947Z",
     "start_time": "2023-10-12T10:07:51.519099Z"
    }
   },
   "id": "bd5060712a89f7eb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# get_preprocessed_dataset_2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84cfed54314319c0"
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "outputs": [],
   "source": [
    "def get_preprocessed_dataset_2(all_df):\n",
    "    '''name을 세 개의 컬럼으로 분리하여 다시 all_df에 합침'''\n",
    "    # , 또는 .을 기준으로 이름을 세 부분으로 분리 ex) Mr.Owen Karris -> Mr 과 Owen 과 Karris로 분리\n",
    "    name_df = all_df[\"Name\"].str.split(\"[,.]\", n=2, expand=True)\n",
    "    # \"family_name,\" \"honorific,\" \"name\" 순서대로 이름이 분리\n",
    "    name_df.columns = [\"family_name\", \"honorific\", \"name\"]\n",
    "    # 각 이름들을 공백을 제거한 형태로 저장\n",
    "    name_df[\"family_name\"] = name_df[\"family_name\"].str.strip()\n",
    "    name_df[\"honorific\"] = name_df[\"honorific\"].str.strip()\n",
    "    name_df[\"name\"] = name_df[\"name\"].str.strip()\n",
    "    # name_df을 열 방향(axis=1)으로 합침\n",
    "    all_df = pd.concat([all_df, name_df], axis=1)\n",
    "\n",
    "    return all_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T10:07:51.889002Z",
     "start_time": "2023-10-12T10:07:51.520195Z"
    }
   },
   "id": "66f3a940eb9bc692"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# get_preprocessed_dataset_3"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "676c5f4d64dcf816"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_preprocessed_dataset_3(all_df):\n",
    "    ''' hoorific별 Age 평균값을 사용하여 Age 결측치 메우기'''\n",
    "    # honorific열 과 Age열을 honorific으로 묶고 중앙을 계산하여 Age값에서 반올림한다.\n",
    "    honorific_age_mean = all_df[[\"honorific\", \"Age\"]].groupby(\"honorific\").median().round().reset_index()\n",
    "    honorific_age_mean.columns = [\"honorific\", \"honorific_age_mean\", ]\n",
    "    # honorific_age_mean 데이터프레임을 honorific 열을 기준으로 left join 하여 병합\n",
    "    # honorific 열을 기준으로 Age 열의 결측치를 honorific_age_mean 값으로 채울 수 있음\n",
    "    all_df = pd.merge(all_df, honorific_age_mean, on=\"honorific\", how=\"left\")\n",
    "    all_df.loc[(all_df[\"Age\"].isnull()), \"Age\"] = all_df[\"honorific_age_mean\"]\n",
    "    # 필요 없어진 honorific_age_mean 열을 삭제\n",
    "    all_df = all_df.drop([\"honorific_age_mean\"], axis=1)\n",
    "\n",
    "    return all_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33e794034f4595e4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# get_preprocessed_dataset_4"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42dcf5b745a1a90b"
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "outputs": [],
   "source": [
    "def get_preprocessed_dataset_4(all_df):\n",
    "    # Parch열 과 SibSp열을 합쳐, 가족수(family_num) 컬럼 새롭게 추가\n",
    "    # Parch : 부모/자녀 수\n",
    "    # SibSp : 형제/자매/배우자 수\n",
    "    all_df[\"family_num\"] = all_df[\"Parch\"] + all_df[\"SibSp\"]\n",
    "    \n",
    "    # 혼자탑습(alone) 컬럼 새롭게 추가\n",
    "    all_df.loc[all_df[\"family_num\"] == 0, \"alone\"] = 1\n",
    "    all_df[\"alone\"].fillna(0, inplace=True)\n",
    "    \n",
    "    # 학습에 불필요한 컬럼 제거\n",
    "    all_df = all_df.drop([\"PassengerId\", \"Name\", \"family_name\", \"name\", \"Ticket\", \"Cabin\"], axis=1)\n",
    "    \n",
    "    return all_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T10:07:51.890392Z",
     "start_time": "2023-10-12T10:07:51.520941Z"
    }
   },
   "id": "29329e8520dd9c19"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# get_preprocessed_dataset_5"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bac2dc6a895f36d8"
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [],
   "source": [
    "def get_preprocessed_dataset_5(all_df):\n",
    "    ''' honorific 값 개수 줄이기'''\n",
    "    # honorific열에서 Mr, Miss, Mrs, Master이 아닌 경우 해당 값을 other로 변경\n",
    "    all_df.loc[\n",
    "    ~(\n",
    "            (all_df[\"honorific\"] == \"Mr\") |\n",
    "            (all_df[\"honorific\"] == \"Miss\") |\n",
    "            (all_df[\"honorific\"] == \"Mrs\") |\n",
    "            (all_df[\"honorific\"] == \"Master\")\n",
    "    ),\n",
    "    \"honorific\"\n",
    "    ] = \"other\"\n",
    "    # fillna 함수를 사용하여 탑승지(Embarked)열의 결측치를 missing으로 변경\n",
    "    # inplace=False가 기본, True로 설정하면 데이터프레임 자체를 변경\n",
    "    all_df[\"Embarked\"].fillna(\"missing\", inplace=True)\n",
    "\n",
    "    return all_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T10:07:51.890444Z",
     "start_time": "2023-10-12T10:07:51.523488Z"
    }
   },
   "id": "6652d43b6f87b42b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# get_preprocessed_dataset_6"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22049e683b992bcd"
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "outputs": [],
   "source": [
    "def get_preprocessed_dataset_6(all_df):\n",
    "    '''카테고리 변수(범주형, 문자열)를 LabelEncoder를 사용하여 수치값(정수)으로 변경하기'''\n",
    "    # all_df에서 데이터 타입이 문자열(object)인 모든 열을 찾아서 category_features에 저장\n",
    "    category_features = all_df.columns[all_df.dtypes == \"object\"]\n",
    "    # LabelEncoder는 범주형 데이터를 정수로 변환하는 데 사용되는 클래스\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    for category_feature in category_features:\n",
    "        le = LabelEncoder()\n",
    "        if all_df[category_feature].dtypes == \"object\":\n",
    "            # fit 메서드를 사용하여 해당 열의 고유한 범주값들을 학습\n",
    "            le = le.fit(all_df[category_feature])\n",
    "            # transform 메서드를 사용하여 해당 열의 모든 값을 해당 범주의 정수로 변환\n",
    "            all_df[category_feature] = le.transform(all_df[category_feature])\n",
    "            \n",
    "    return all_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T10:07:51.890475Z",
     "start_time": "2023-10-12T10:07:51.525792Z"
    }
   },
   "id": "f494a131908fb0ca"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 신경망 정의"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ffd8a3aa9d37f3a"
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class MyModel(nn.Module):\n",
    "    '''신경망 정의 / MyModel클래스는 nn.Module클래스를 상속받아 pytorch의 모델 기능을 활용할 수 있도록 함'''\n",
    "    # input : feature의 수\n",
    "    # n_output : 출력되어 나오는 결과\n",
    "    def __init__(self, n_input, n_output):\n",
    "        # 부모 클래스의 nn.Module의 생성자를 호출\n",
    "        super().__init__()\n",
    "        \n",
    "        # 시퀀셜(Sequential) 모델을 사용, 이를 통해 여러 계층을 순차적으로 쌓을 수 있음\n",
    "        # 시퀀셜 모델은 각 계층을 순차적으로 연결\n",
    "        self.model = nn.Sequential(\n",
    "            # n_input에서 30개의 뉴런을 가진 완전 연결 레이어를 생성\n",
    "            nn.Linear(n_input, 30),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(30, 30),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(30, n_output),\n",
    "        \n",
    "            # 30개의 뉴런에서 출력 클래스 수 n_output으로 연결\n",
    "            #nn.Linear(30, n_output),\n",
    "        )\n",
    "        \n",
    "    # foward\n",
    "    #  모델에 입력 데이터 x를 전달하여 출력을 반환\n",
    "    def forward(self, x):\n",
    "        # 입력 데이터 x를 모델의 시퀀셜 레이어에 전달하여 feed fowarding 수행\n",
    "        x = self.model(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T10:07:51.890539Z",
     "start_time": "2023-10-12T10:07:51.528795Z"
    }
   },
   "id": "6a8200f528599014"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# test"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4fc44c1816ab95"
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [],
   "source": [
    "def test(test_data_loader):\n",
    "    '''모델을 테스트 하는 부분'''\n",
    "    print(\"[TEST]\")\n",
    "    # iter를 사용하여 감싸준 다음 next를 사용하여 첫번째 미니배치를 배치로 넘김\n",
    "    batch = next(iter(test_data_loader))\n",
    "    print(\"{0}\".format(batch['input'].shape))\n",
    "    my_model = MyModel(n_input=11, n_output=2)\n",
    "    output_batch = my_model(batch['input'])\n",
    "    # 모델의 출력 중에서 각 샘플에 대한 가장 높은 값을 가진 클래스의 인덱스를 선택하여 예측\n",
    "    prediction_batch = torch.argmax(output_batch, dim=1)\n",
    "    # 인덱스를 892부터 시작하도록 설정, 첫번째 테스트 데이터의 인덱스 번째\n",
    "    for idx, prediction in enumerate(prediction_batch, start=892):\n",
    "        print(idx, prediction.item())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T10:07:51.890603Z",
     "start_time": "2023-10-12T10:07:51.533501Z"
    }
   },
   "id": "a912a2e9ff5afe00"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# main문"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "deb6f05e044ce7c2"
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.15.12"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/Users/hong/git/link_dl/_02_homeworks/_02_fcn_dl/titanic/wandb/run-20231012_190106-yym5pglx</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/honguc/titanic/runs/yym5pglx' target=\"_blank\">LeakyReLU(0.1)</a></strong> to <a href='https://wandb.ai/honguc/titanic' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/honguc/titanic' target=\"_blank\">https://wandb.ai/honguc/titanic</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/honguc/titanic/runs/yym5pglx' target=\"_blank\">https://wandb.ai/honguc/titanic/runs/yym5pglx</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################## 3\n",
      "[TEST]\n",
      "torch.Size([418, 11])\n",
      "892 0\n",
      "893 0\n",
      "894 0\n",
      "895 0\n",
      "896 0\n",
      "897 0\n",
      "898 0\n",
      "899 0\n",
      "900 0\n",
      "901 0\n",
      "902 0\n",
      "903 0\n",
      "904 0\n",
      "905 0\n",
      "906 0\n",
      "907 0\n",
      "908 0\n",
      "909 0\n",
      "910 0\n",
      "911 0\n",
      "912 0\n",
      "913 0\n",
      "914 0\n",
      "915 0\n",
      "916 0\n",
      "917 0\n",
      "918 0\n",
      "919 0\n",
      "920 0\n",
      "921 0\n",
      "922 0\n",
      "923 0\n",
      "924 0\n",
      "925 0\n",
      "926 0\n",
      "927 0\n",
      "928 0\n",
      "929 0\n",
      "930 0\n",
      "931 0\n",
      "932 0\n",
      "933 0\n",
      "934 0\n",
      "935 0\n",
      "936 0\n",
      "937 0\n",
      "938 0\n",
      "939 0\n",
      "940 0\n",
      "941 0\n",
      "942 0\n",
      "943 0\n",
      "944 0\n",
      "945 0\n",
      "946 0\n",
      "947 0\n",
      "948 0\n",
      "949 0\n",
      "950 0\n",
      "951 0\n",
      "952 0\n",
      "953 0\n",
      "954 0\n",
      "955 0\n",
      "956 0\n",
      "957 0\n",
      "958 0\n",
      "959 0\n",
      "960 0\n",
      "961 0\n",
      "962 0\n",
      "963 0\n",
      "964 0\n",
      "965 0\n",
      "966 0\n",
      "967 0\n",
      "968 0\n",
      "969 0\n",
      "970 0\n",
      "971 0\n",
      "972 0\n",
      "973 0\n",
      "974 0\n",
      "975 0\n",
      "976 0\n",
      "977 0\n",
      "978 0\n",
      "979 0\n",
      "980 0\n",
      "981 0\n",
      "982 0\n",
      "983 0\n",
      "984 0\n",
      "985 0\n",
      "986 0\n",
      "987 0\n",
      "988 0\n",
      "989 0\n",
      "990 0\n",
      "991 0\n",
      "992 0\n",
      "993 0\n",
      "994 0\n",
      "995 0\n",
      "996 0\n",
      "997 0\n",
      "998 0\n",
      "999 0\n",
      "1000 0\n",
      "1001 0\n",
      "1002 0\n",
      "1003 0\n",
      "1004 0\n",
      "1005 0\n",
      "1006 0\n",
      "1007 0\n",
      "1008 0\n",
      "1009 0\n",
      "1010 0\n",
      "1011 0\n",
      "1012 0\n",
      "1013 0\n",
      "1014 0\n",
      "1015 0\n",
      "1016 0\n",
      "1017 0\n",
      "1018 0\n",
      "1019 0\n",
      "1020 0\n",
      "1021 0\n",
      "1022 0\n",
      "1023 0\n",
      "1024 0\n",
      "1025 0\n",
      "1026 0\n",
      "1027 0\n",
      "1028 0\n",
      "1029 0\n",
      "1030 0\n",
      "1031 0\n",
      "1032 0\n",
      "1033 0\n",
      "1034 0\n",
      "1035 0\n",
      "1036 0\n",
      "1037 0\n",
      "1038 0\n",
      "1039 0\n",
      "1040 0\n",
      "1041 0\n",
      "1042 0\n",
      "1043 0\n",
      "1044 0\n",
      "1045 0\n",
      "1046 0\n",
      "1047 0\n",
      "1048 0\n",
      "1049 0\n",
      "1050 0\n",
      "1051 0\n",
      "1052 0\n",
      "1053 0\n",
      "1054 0\n",
      "1055 0\n",
      "1056 0\n",
      "1057 0\n",
      "1058 0\n",
      "1059 0\n",
      "1060 0\n",
      "1061 0\n",
      "1062 0\n",
      "1063 0\n",
      "1064 0\n",
      "1065 0\n",
      "1066 0\n",
      "1067 0\n",
      "1068 0\n",
      "1069 0\n",
      "1070 0\n",
      "1071 0\n",
      "1072 0\n",
      "1073 0\n",
      "1074 0\n",
      "1075 0\n",
      "1076 0\n",
      "1077 0\n",
      "1078 0\n",
      "1079 0\n",
      "1080 0\n",
      "1081 0\n",
      "1082 0\n",
      "1083 0\n",
      "1084 0\n",
      "1085 0\n",
      "1086 0\n",
      "1087 0\n",
      "1088 0\n",
      "1089 0\n",
      "1090 0\n",
      "1091 0\n",
      "1092 0\n",
      "1093 0\n",
      "1094 0\n",
      "1095 0\n",
      "1096 0\n",
      "1097 0\n",
      "1098 0\n",
      "1099 0\n",
      "1100 0\n",
      "1101 0\n",
      "1102 0\n",
      "1103 0\n",
      "1104 0\n",
      "1105 0\n",
      "1106 0\n",
      "1107 0\n",
      "1108 0\n",
      "1109 0\n",
      "1110 0\n",
      "1111 0\n",
      "1112 0\n",
      "1113 0\n",
      "1114 0\n",
      "1115 0\n",
      "1116 0\n",
      "1117 0\n",
      "1118 0\n",
      "1119 0\n",
      "1120 0\n",
      "1121 0\n",
      "1122 0\n",
      "1123 0\n",
      "1124 0\n",
      "1125 0\n",
      "1126 0\n",
      "1127 0\n",
      "1128 0\n",
      "1129 0\n",
      "1130 0\n",
      "1131 0\n",
      "1132 0\n",
      "1133 0\n",
      "1134 0\n",
      "1135 0\n",
      "1136 0\n",
      "1137 0\n",
      "1138 0\n",
      "1139 0\n",
      "1140 0\n",
      "1141 0\n",
      "1142 0\n",
      "1143 0\n",
      "1144 0\n",
      "1145 0\n",
      "1146 0\n",
      "1147 0\n",
      "1148 0\n",
      "1149 0\n",
      "1150 0\n",
      "1151 0\n",
      "1152 0\n",
      "1153 0\n",
      "1154 0\n",
      "1155 0\n",
      "1156 0\n",
      "1157 0\n",
      "1158 0\n",
      "1159 0\n",
      "1160 0\n",
      "1161 0\n",
      "1162 0\n",
      "1163 0\n",
      "1164 0\n",
      "1165 0\n",
      "1166 0\n",
      "1167 0\n",
      "1168 0\n",
      "1169 0\n",
      "1170 0\n",
      "1171 0\n",
      "1172 0\n",
      "1173 0\n",
      "1174 0\n",
      "1175 0\n",
      "1176 0\n",
      "1177 0\n",
      "1178 0\n",
      "1179 0\n",
      "1180 0\n",
      "1181 0\n",
      "1182 0\n",
      "1183 0\n",
      "1184 0\n",
      "1185 0\n",
      "1186 0\n",
      "1187 0\n",
      "1188 0\n",
      "1189 0\n",
      "1190 0\n",
      "1191 0\n",
      "1192 0\n",
      "1193 0\n",
      "1194 0\n",
      "1195 0\n",
      "1196 0\n",
      "1197 0\n",
      "1198 0\n",
      "1199 0\n",
      "1200 0\n",
      "1201 0\n",
      "1202 0\n",
      "1203 0\n",
      "1204 0\n",
      "1205 0\n",
      "1206 0\n",
      "1207 0\n",
      "1208 0\n",
      "1209 0\n",
      "1210 0\n",
      "1211 0\n",
      "1212 0\n",
      "1213 0\n",
      "1214 0\n",
      "1215 0\n",
      "1216 0\n",
      "1217 0\n",
      "1218 0\n",
      "1219 0\n",
      "1220 0\n",
      "1221 0\n",
      "1222 0\n",
      "1223 0\n",
      "1224 0\n",
      "1225 0\n",
      "1226 0\n",
      "1227 0\n",
      "1228 0\n",
      "1229 0\n",
      "1230 0\n",
      "1231 0\n",
      "1232 0\n",
      "1233 0\n",
      "1234 0\n",
      "1235 0\n",
      "1236 0\n",
      "1237 0\n",
      "1238 0\n",
      "1239 0\n",
      "1240 0\n",
      "1241 0\n",
      "1242 0\n",
      "1243 0\n",
      "1244 0\n",
      "1245 0\n",
      "1246 0\n",
      "1247 0\n",
      "1248 0\n",
      "1249 0\n",
      "1250 0\n",
      "1251 0\n",
      "1252 0\n",
      "1253 0\n",
      "1254 0\n",
      "1255 0\n",
      "1256 0\n",
      "1257 0\n",
      "1258 0\n",
      "1259 0\n",
      "1260 0\n",
      "1261 0\n",
      "1262 0\n",
      "1263 0\n",
      "1264 0\n",
      "1265 0\n",
      "1266 0\n",
      "1267 0\n",
      "1268 0\n",
      "1269 0\n",
      "1270 0\n",
      "1271 0\n",
      "1272 0\n",
      "1273 0\n",
      "1274 0\n",
      "1275 0\n",
      "1276 0\n",
      "1277 0\n",
      "1278 0\n",
      "1279 0\n",
      "1280 0\n",
      "1281 0\n",
      "1282 0\n",
      "1283 0\n",
      "1284 0\n",
      "1285 0\n",
      "1286 0\n",
      "1287 0\n",
      "1288 0\n",
      "1289 0\n",
      "1290 0\n",
      "1291 0\n",
      "1292 0\n",
      "1293 0\n",
      "1294 0\n",
      "1295 0\n",
      "1296 0\n",
      "1297 0\n",
      "1298 0\n",
      "1299 0\n",
      "1300 0\n",
      "1301 0\n",
      "1302 0\n",
      "1303 0\n",
      "1304 0\n",
      "1305 0\n",
      "1306 0\n",
      "1307 0\n",
      "1308 0\n",
      "1309 0\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1c83d07ca95d45ba845b059eb9c70336"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training Loss</td><td>█▇▇▇▆▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▁</td></tr><tr><td>Validation Accuracy</td><td>▂▃▁▃▃▂▄▃▅▅▅▅▅▁▆▄▅▇▆▄▇▇▇▆▄▇▆█▄▅▃▅▃█▅▂▆▆▄▇</td></tr><tr><td>Validation Loss</td><td>▄▅▅▅▄▄▄▇▂▄▃▂▃█▂▅▅▄▂▄▂▁▃▂▄▂▂▁▃▃█▃▅▁▃▇▂▂▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training Loss</td><td>0.39677</td></tr><tr><td>Validation Accuracy</td><td>77.52809</td></tr><tr><td>Validation Loss</td><td>0.55895</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">LeakyReLU(0.1)</strong> at: <a href='https://wandb.ai/honguc/titanic/runs/yym5pglx' target=\"_blank\">https://wandb.ai/honguc/titanic/runs/yym5pglx</a><br/> View job at <a href='https://wandb.ai/honguc/titanic/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEwNjE1MzU0Nw==/version_details/v1' target=\"_blank\">https://wandb.ai/honguc/titanic/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEwNjE1MzU0Nw==/version_details/v1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>./wandb/run-20231012_190106-yym5pglx/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # wandb 초기화\n",
    "    wandb.init(project=\"titanic\", name=\"ReLU\")\n",
    "    \n",
    "    train_dataset, validation_dataset, test_dataset = get_preprocessed_dataset()\n",
    "\n",
    "    print(\"train_dataset: {0}, validation_dataset.shape: {1}, test_dataset: {2}\".format(\n",
    "        len(train_dataset), len(validation_dataset), len(test_dataset)\n",
    "    ))\n",
    "    print(\"#\" * 50, 1)\n",
    "\n",
    "    for idx, sample in enumerate(train_dataset):\n",
    "        print(\"{0} - {1}: {2}\".format(idx, sample['input'], sample['target']))\n",
    "\n",
    "    print(\"#\" * 50, 2)\n",
    "\n",
    "    train_data_loader = DataLoader(dataset=train_dataset, batch_size=16, shuffle=True)\n",
    "    validation_data_loader = DataLoader(dataset=validation_dataset, batch_size=16, shuffle=True)\n",
    "    test_data_loader = DataLoader(dataset=test_dataset, batch_size=len(test_dataset))\n",
    "\n",
    "    # 모델 정의\n",
    "    my_model = MyModel(n_input=11, n_output=2)\n",
    "\n",
    "    # 손실 함수 정의 (예: 크로스 엔트로피)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # 옵티마이저 설정 (예: 확률적 경사 하강법 - SGD)\n",
    "    optimizer = torch.optim.SGD(my_model.parameters(), lr=0.01)\n",
    "\n",
    "    # 학습 루프\n",
    "    num_epochs = 1500  # 에폭 수를 설정\n",
    "    for epoch in range(num_epochs):\n",
    "        my_model.train()  # 모델을 학습 모드로 설정\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for batch in train_data_loader:\n",
    "            inputs = batch['input']\n",
    "            labels = batch['target']\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = my_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Training loss를 wandb에 기록\n",
    "        wandb.log({\"Training Loss\": running_loss / len(train_data_loader)})\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}, Training Loss: {running_loss / len(train_data_loader)}\")\n",
    "\n",
    "        # 검증 부분\n",
    "        my_model.eval()  # 모델을 평가 모드로 설정\n",
    "        validation_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in validation_data_loader:\n",
    "                inputs = batch['input']\n",
    "                labels = batch['target']\n",
    "\n",
    "                outputs = my_model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                validation_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        \n",
    "        # Validation loss와 accuracy를 wandb에 기록\n",
    "        wandb.log({\"Validation Loss\": validation_loss / len(validation_data_loader), \"Validation Accuracy\": accuracy})\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}, Validation Loss: {validation_loss / len(validation_data_loader)}, Validation Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    print(\"#\" * 50, 3)\n",
    "\n",
    "    # 테스트 함수 호출\n",
    "    test(test_data_loader)\n",
    "    \n",
    "    wandb.finish()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T10:01:20.681052Z",
     "start_time": "2023-10-12T10:01:06.287463Z"
    }
   },
   "id": "a7cc784478602326"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
